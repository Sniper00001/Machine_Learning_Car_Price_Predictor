# -*- coding: utf-8 -*-
"""Project_2_ML_Car_Price_Predictor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j4oe_KLaX4pysLZVfmK-wzUkvNnJZKvP

So once your family planned to sell the car which you have. They are just thinking that how much money they will get by selling your car.

Suddenly your relative came he also discussed the same problem they are also planning to sell their car but have no idea that how much money they will get.

Now to help everyone you took this problem on your hands and by using your Machine Learning skills you will find approximate how much money your family and your relative’s family will get by selling their cars.

How can we import the needed libraries ?
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""How can we import the dataset ?"""

from google.colab import drive
drive.mount('/content/drive')

car=pd.read_csv('/content/drive/MyDrive/cars_data.csv')

"""How can we see the first 5 rows of data ?"""

car.head()

"""How can we find the number of rows and columns in the data ?"""

car.shape

"""How can we find the basic info about the data like data type of different columns, null and non-null contents ?"""

car.info()

"""# Data Analysis and Cleaning

### Now we are going to analyse the different columns of data and see what are the problems which they have and how can we sort them.

How can we find the types of unique data in year column ?
"""

car['year'].unique()

car['name'].unique()

"""
1. Names are pretty inconsistent
2. There are non-name values
3. some names are spam like 'Maruti Ertiga showroom condition with' and 'Well mentained Tata Sumo'"""

car['company'].unique()

"""
1. Names are pretty inconsistent
2. They are having non-company values."""

car['Price'].unique()

"""
1. It in object should be in int type.
2. It is having non-Price data like 'Ask for Price'
3. It shouldn't have commas between price else we'll not be able to do mathematical operations."""

car['kms_driven'].unique()

"""
1. Its in object should be in int type.
2. It is having kms in last and is having commas."""

car['fuel_type'].unique()

"""1. Its in object should be in int type.
2. It is having nan as data type which should not be there.

## Quality
* names are pretty inconsistent
* names have company names attached to it
* some names are spam like 'Maruti Ertiga showroom condition with' and 'Well mentained Tata Sumo'
* company: many of the names are not of any company like 'Used', 'URJENT', and so on.
* year has many non-year values
* year is in object. Change to integer
* Price has Ask for Price
* Price has commas in its prices
* Price is in object should be in int
* kms_driven has object values with kms at last
* It has nan values and two rows have 'Petrol' in them
* fuel_type has nan values

How can we make the copy of data ?
"""

backup = car.copy()

"""How can we choose only numeric values in year column and remove all other values ?"""

car = car[car['year'].str.isnumeric()]

"""How to convert data type of year column from object to int ?"""

car['year']= car['year'].astype(int)

"""Let's check if it is changed."""

car.info()

"""Let's check car Price now"""

car['Price']

"""How to remove the 'Ask for Price' from Price column ?"""

car = car[car['Price']!='Ask For Price']

"""Check it again."""

car['Price']

"""How we can remove commas from Price column and also convert it to int ?"""

car['Price'] = car['Price'].str.replace(',','').astype(int)

car['Price']

"""Let's now check the kms_driven column.

"""

car['kms_driven']

"""How can we remove the kms from last and also remove the commas from number of kms ?"""

car['kms_driven'] = car['kms_driven'].str.split(' ').str.get(0).str.replace(',','')

"""Now the kms_driven is also having non-numerical values we need to remove them and we need only numerical or integer values.  """

car= car[car['kms_driven'].str.isnumeric()]

"""Let's convert the data type of kms_driven from object to integer."""

car['kms_driven']=car['kms_driven'].astype(int)

"""Let's see the car now."""

car.info()

car

"""Now let's clean the case where fuel_type data is not available."""

car = car[~car['fuel_type'].isna()]

"""We were having another very big problem in the names column the names were very ambiguous so what we are going to do is that we are going to make it only 2 words. Let's see how we can do it."""

car['name'] = car['name'].str.split(' ').str.slice(0,3).str.join(' ')

car

"""We want to remove outliers that means a data which is too much. It may change/disturb the predictions of other datas. Hence we'll remove them. Generally such values are ther because of mistake. We'll remove the car which have price more than 50 lakhs."""

car[car['Price']>5000000]

car = car[car['Price']<5000000].reset_index(drop=True)

"""Similarly we have seen there is just one car which has run more than 3 lakh km so we'll remove that one too."""

car = car[car['kms_driven']<300000].reset_index(drop=True)

car.info()

car.to_csv('Cleaned_Car_Data.csv')

car.info()

car.describe(include='all')

"""### Checking relationship of Company with Price"""

car['company'].unique()

plt.subplots(figsize=(15,7))
ax=sns.boxplot(x='company',y='Price',data=car)
plt.ticklabel_format(style='plain', axis='y') # Here in x-axis we can see that the data is overlapped
plt.show()

plt.subplots(figsize=(15,7))
ax=sns.boxplot(x='company',y='Price',data=car)
ax.set_xticklabels(ax.get_xticklabels(),rotation=40,ha='right') # Please observe we have tilted names by 40 degree using rotation
plt.show()

"""### Checking relationship of Year with Price"""

plt.subplots(figsize=(20,10))
ax=sns.swarmplot(x='year',y='Price',data=car)
ax.set_xticklabels(ax.get_xticklabels(),rotation=40,ha='right')
plt.show()

"""### Checking relationship of kms_driven with Price"""

sns.relplot(x='kms_driven',y='Price',data=car,height=7,aspect=1.5)

"""### Checking relationship of Fuel Type with Price"""

plt.subplots(figsize=(14,7))
sns.boxplot(x='fuel_type',y='Price',data=car)
plt.ticklabel_format(style='plain', axis='y')

"""### Relationship of Price with FuelType, Year and Company mixed"""

ax=sns.relplot(x='company',y='Price',data=car,hue='fuel_type',size='year',height=7,aspect=2)
ax.set_xticklabels(rotation=40,ha='right')

"""### Extracting Training Data

Let's make 2 different data frames in which one will contain other details and other will contain only price which we have to predict.
"""

X=car[['name','company','year','kms_driven','fuel_type']]
y=car['Price']

X['name'].describe()

y.shape

"""## Model

Can also be written like this where only to drop price.
"""

X = car.drop(columns='Price')
y = car['Price']

car.head()

"""Here we are splitting the data in 4 parts:"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)

"""We are importing different things from sklearn. Let's see them one by one.


*   r2_score :  "Coefficient of determination also called as R2 score is used to evaluate the performance of a linear regression model." It is the amount of the variation in the output dependent attribute which is predictable from the input independent variable(s).
Best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a  score of 0.0.

*   OneHotEncoder:  Machines understand numbers, not text. We need to convert each text category to numbers in order for the machine to process them using mathematical equations.That’s primarily the reason we need to convert categorical columns to numerical columns so that a machine learning algorithm understands it. This process is called categorical encoding.
One-Hot Encoding is another popular technique for treating categorical variables. It simply creates additional features based on the number of unique values in the categorical feature. Every unique value in the category will be added as a feature.
  One-Hot Encoding is the process of creating dummy variables.

*  Pipeline : Machine Learning projects need iterative progress. For example, we clean and prepare data for modeling with transforming to the proper format, run the model, get results, improve the model/change the model and work on feature engineering, get new results, compare them with other results, etc. It is not easy and smart to do every step again and again. To solve this problem, we can use a pipeline to integrate steps of machine learning workflow.
Pipelines are super useful for transforming and training data quickly.



"""

from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import make_column_transformer
from sklearn.pipeline import make_pipeline

ohe = OneHotEncoder()
ohe.fit(X[['name','company','fuel_type']]) # We created onehotencoder

ohe.categories_

column_trans = make_column_transformer((OneHotEncoder(categories=ohe.categories_),['name','company','fuel_type']), remainder='passthrough')
# remainder = passthrough means passing columns which are not transformed as it is.

lr = LinearRegression()

pipe = make_pipeline(column_trans,lr) # Made pipeline and saved it in variable named pipe
# What pipeline did was it transformed the columns which were needed and than passed in to linear regresssion.

pipe.fit(X_train, y_train) # Trained the pipe

y_pred = pipe.predict(X_test) # saved the prediction for test values in y_pred

r2_score(y_test, y_pred) # Calculated the score of prediction.

"""#### Finding the model with a random state of TrainTestSplit where the model was found to give better score

when random_state set to an integer, train_test_split will return same results for each execution.

when random_state set to an None, train_test_split will return different results for each execution.
"""

scores=[] # We made list named as scores.

for i in range(1000):

    X_train, X_test, y_train, y_test = train_test_split ( X, y, test_size=0.1, random_state=i) # We have run the loop by using different random state.

    lr=LinearRegression()

    pipe=make_pipeline(column_trans,lr)

    pipe.fit(X_train,y_train)

    y_pred=pipe.predict(X_test)

    scores.append(r2_score(y_test,y_pred))

np.argmax(scores) # This finds the value where score was the highest

scores[np.argmax(scores)] # Now the scores are 94 percent.

"""#### The best model is found at a certain random state"""

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.1,random_state=np.argmax(scores))

lr=LinearRegression()

pipe=make_pipeline(column_trans,lr)

pipe.fit(X_train,y_train)

y_pred=pipe.predict(X_test)

r2_score(y_test,y_pred)

car['name'].value_counts().head(15)

car[car['name']=='Honda City' ]

car_name = input("Please Enter the Car Name ")
company = input("Please Enter the company name ")
year = int(input("Please enter the year in which it has been bought "))
km_travelled = int(input("Please enter the number of km it has travelled "))
typefuel = input("Please enter the type of fuel it uses Petrol/Diesel/LPG ")


PredictedPrice = pipe.predict(pd.DataFrame(columns=X_test.columns,data=np.array([car_name,company,year,km_travelled,typefuel]).reshape(1,5)))

print("Hence according to algorithm the predicted price is ", round(PredictedPrice[0],2))

pipe.predict(pd.DataFrame(columns=X_test.columns,data=np.array(['Maruti Suzuki Alto','Maruti',2015,100,'Petrol']).reshape(1,5)))

"""Let's dump the model.

How to dump a model ?
"""

import pickle

pickle.dump(pipe,open('LinearRegressionModel.pkl','wb'))